---
layout: post
title: "What is robots.txt?"
date: 2018-11-18 00:32:22 -0600
categories: jekyll update
---

## The robots.txt file
The `robots.txt` file is a special file which tells web crawlers what parts of the website they should (be able to) crawl. It's most common use is for describing what parts of the site crawlers should not index, such duplicated or irrelevant URLs. The file is placed in the root directory of the web server (eg. /robots.txt).

It is important to know that crawlers can potentially ignore following the rules specified in robots.txt. Malicious crawlers may also use any `User-agent`. Since the file is publically available, everyone can also see what parts of the site you don't want to show to the web crawlers. Because of this, the robots.txt file should never be used to denote private sections of the website!


## Use of robots.txt on this site
The *robots.txt* for this site is as simple as it gets; it simply tells all crawlers that they can crawl the whole site with no restrictions.

{% highlight yml %}
User-agent: *
Disallow:
{% endhighlight %}
